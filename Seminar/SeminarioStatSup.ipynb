{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Seminario Statistica Superiore: codice**"
      ],
      "metadata": {
        "id": "p-mVH9xEx4zT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DA18ZfTfxhcn"
      },
      "source": [
        "##**Figure Seminario**\n",
        "\n",
        "\n",
        "Per il codice in questa sezione ho preso spunto da: \n",
        "1. https://github.com/ageron/handson-ml2/blob/master/04_training_linear_models.ipynb (per i grafici su gd-sgd-mb)\n",
        "2. https://bayes-logistic.readthedocs.io/en/latest/usage.html (per capire la libreria bayes_logistic)\n",
        "3. https://github.com/probml/pyprobml/tree/master/scripts (per i grafici su bayes logistic regression)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQ370RW3zf4U"
      },
      "outputs": [],
      "source": [
        "pip install bayes_logistic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eao_Nn232jSF"
      },
      "outputs": [],
      "source": [
        "pip install superimport"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_H8RqAiPxiLr"
      },
      "outputs": [],
      "source": [
        "#importo le librerie utilizzate\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "from sklearn import metrics\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt \n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import log_loss\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras import regularizers\n",
        "from keras import optimizers\n",
        "\n",
        "\n",
        "import superimport\n",
        "from scipy.stats import norm, multivariate_normal\n",
        "from scipy.special import expit\n",
        "import bayes_logistic \n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
        "\n",
        "\n",
        "\n",
        "#per i plot\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7rkHpUuyPR8"
      },
      "source": [
        "###Esempio ad hoc per confrontare gd-sgd-mb \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6O8shsinxifC"
      },
      "outputs": [],
      "source": [
        "#genero i dati\n",
        "np.random.seed(40)\n",
        "X = 2 * np.random.rand(100, 1)\n",
        "y = 4 + 3 * X + np.random.randn(100, 1)\n",
        "X_b = np.c_[np.ones((100, 1)), X]\n",
        "theta_best = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)\n",
        "X_new = np.array([[0], [2]])\n",
        "X_new_b = np.c_[np.ones((2, 1)), X_new]\n",
        "y_predict = X_new_b.dot(theta_best)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FHs9B1EqpOo"
      },
      "outputs": [],
      "source": [
        "plt.plot(X_new, y_predict, \"r-\")\n",
        "plt.plot(X, y, \"b.\")\n",
        "plt.axis([0, 2, 0, 15])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HghU8UL-yq0b"
      },
      "source": [
        "##Gradient descent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1dQN6cW_xixd"
      },
      "outputs": [],
      "source": [
        "#implemento solo il caso di linear regression, più semplice\n",
        "eta = 0.1  # learning rate\n",
        "n_iterations = 1000\n",
        "m = 100\n",
        "\n",
        "theta_path_bgd = []\n",
        "theta = np.random.randn(2,1) \n",
        "\n",
        "def gradient_descent_path(theta, eta, theta_path=None):\n",
        "    m = len(X_b)\n",
        "    n_iterations = 1000\n",
        "    for iteration in range(n_iterations):\n",
        "        if iteration < 10:\n",
        "            y_predict = X_new_b.dot(theta)\n",
        "        gradients = 2/m * X_b.T.dot(X_b.dot(theta) - y)\n",
        "        theta = theta - eta * gradients\n",
        "        if theta_path is not None:\n",
        "            theta_path.append(theta)\n",
        "\n",
        "\n",
        "gradient_descent_path(theta, eta=0.1, theta_path=theta_path_bgd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z23m7gaZzBwo"
      },
      "source": [
        "###Stochastic Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGD7djofqWc2"
      },
      "outputs": [],
      "source": [
        "theta_path_sgd = []\n",
        "m = len(X_b)\n",
        "np.random.seed(40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlz2vnMXxjD7"
      },
      "outputs": [],
      "source": [
        "n_epochs = 50\n",
        "t0, t1 = 5, 50  \n",
        "\n",
        "def learning_schedule(t):\n",
        "    return t0 / (t + t1)\n",
        "\n",
        "theta = np.random.randn(2,1)  \n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for i in range(m):\n",
        "        if epoch == 0 and i < 20:                    \n",
        "            y_predict = X_new_b.dot(theta)          \n",
        "            style = \"b-\" if i > 0 else \"r--\"        \n",
        "            plt.plot(X_new, y_predict, style)       \n",
        "        random_index = np.random.randint(m)\n",
        "        xi = X_b[random_index:random_index+1]\n",
        "        yi = y[random_index:random_index+1]\n",
        "        gradients = 2 * xi.T.dot(xi.dot(theta) - yi)\n",
        "        eta = learning_schedule(epoch * m + i)\n",
        "        theta = theta - eta * gradients\n",
        "        theta_path_sgd.append(theta)                \n",
        "\n",
        "plt.plot(X, y, \"b.\")                                \n",
        "plt.xlabel(\"$x_1$\", fontsize=18)                    \n",
        "plt.ylabel(\"$y$\", rotation=0, fontsize=18)          \n",
        "plt.axis([0, 2, 0, 15])                             \n",
        "plt.savefig(\"sgd_plot\")                                \n",
        "plt.show()                                          "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZkalIvOzS3U"
      },
      "source": [
        "###Mini-batch gradient descent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQ6pd6XDzWYs"
      },
      "outputs": [],
      "source": [
        "theta_path_mgd = []\n",
        "\n",
        "n_iterations = 50\n",
        "minibatch_size = 20\n",
        "\n",
        "np.random.seed(40)\n",
        "theta = np.random.randn(2,1)  # random initialization\n",
        "\n",
        "t0, t1 = 200, 1000\n",
        "def learning_schedule(t):\n",
        "    return t0 / (t + t1)\n",
        "\n",
        "t = 0\n",
        "for epoch in range(n_iterations):\n",
        "    shuffled_indices = np.random.permutation(m)\n",
        "    X_b_shuffled = X_b[shuffled_indices]\n",
        "    y_shuffled = y[shuffled_indices]\n",
        "    for i in range(0, m, minibatch_size):\n",
        "        t += 1\n",
        "        xi = X_b_shuffled[i:i+minibatch_size]\n",
        "        yi = y_shuffled[i:i+minibatch_size]\n",
        "        gradients = 2/minibatch_size * xi.T.dot(xi.dot(theta) - yi)\n",
        "        eta = learning_schedule(t)\n",
        "        theta = theta - eta * gradients\n",
        "        theta_path_mgd.append(theta)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMoHKjQezqSx"
      },
      "source": [
        "###Confronto tra i learning algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnNRHQOOzqA5"
      },
      "outputs": [],
      "source": [
        "#trasformo in np.array\n",
        "theta_path_bgd = np.array(theta_path_bgd)\n",
        "theta_path_sgd = np.array(theta_path_sgd)\n",
        "theta_path_mgd = np.array(theta_path_mgd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHExDDeiznDU"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(7,4))\n",
        "plt.plot(theta_path_sgd[:, 0], theta_path_sgd[:, 1], \"r-s\", linewidth=1, label=\"Stochastic\")\n",
        "plt.plot(theta_path_mgd[:, 0], theta_path_mgd[:, 1], \"g-+\", linewidth=2, label=\"Mini-batch\")\n",
        "plt.plot(theta_path_bgd[:, 0], theta_path_bgd[:, 1], \"b-o\", linewidth=3, label=\"Batch\")\n",
        "plt.legend(loc=\"upper left\", fontsize=16)\n",
        "plt.xlabel(r\"$\\theta_0$\", fontsize=20)\n",
        "plt.ylabel(r\"$\\theta_1$   \", fontsize=20, rotation=0)\n",
        "plt.axis([2.5, 4.5, 2.3, 3.9])\n",
        "plt.savefig(\"gradient_descent_paths_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WL-G201syFBW"
      },
      "source": [
        "###Bayesian logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTXUqa7109hu"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "#creo i dati\n",
        "N = 30\n",
        "D = 2\n",
        "mu1 = np.hstack((np.ones((N,1)), 5 * np.ones((N, 1))))\n",
        "mu2 = np.hstack((-5 * np.ones((N,1)), np.ones((N, 1))))\n",
        "class1_std = 1\n",
        "class2_std = 1.1\n",
        "X_1 = np.add(class1_std*np.random.randn(N,2), mu1)\n",
        "X_2 = np.add(2*class2_std*np.random.randn(N,2), mu2)\n",
        "X = np.vstack((X_1,X_2))\n",
        "t = np.vstack((np.ones((N,1)),np.zeros((N,1))))\n",
        "\n",
        "#plotto i dati\n",
        "x_1, y_1 = X[np.where(t==1)[0]].T\n",
        "x_2, y_2 = X[np.where(t==0)[0]].T\n",
        "plt.figure(0)\n",
        "plt.scatter(x_1,y_1,c = 'red', s=20, marker = 'o')\n",
        "plt.scatter(x_2,y_2,c = 'blue', s = 20, marker = 'o')\n",
        "\n",
        "#plotto le ltu\n",
        "alpha = 100\n",
        "Range = 8\n",
        "step = 0.1\n",
        "xx, yy = np.meshgrid(np.arange(-Range,Range,step),np.arange(-Range,Range,step))\n",
        "[n,n] = xx.shape\n",
        "W = np.hstack((xx.reshape((n*n, 1)),yy.reshape((n*n, 1))))\n",
        "Xgrid = W\n",
        "ws = np.array([[3, 1], [4, 2], [5, 3], [7, 3]])\n",
        "col = ['black', 'red', 'green', 'blue']\n",
        "for ii in range(ws.shape[0]):\n",
        "    w = ws[ii][:]\n",
        "    pred = 1.0/(1+np.exp(np.dot(-Xgrid,w)))\n",
        "    plt.contour(xx, yy, pred.reshape((n, n)), 1, colors=col[ii])\n",
        "plt.title(\"dati\")\n",
        "plt.savefig('bayesian_1_.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XorG3C251C6j"
      },
      "outputs": [],
      "source": [
        "#log-likelihood\n",
        "Xt = np.transpose(X)\n",
        "f=np.dot(W,Xt)\n",
        "log_prior = np.log(multivariate_normal.pdf(W, cov=(np.identity(D))*alpha))\n",
        "\n",
        "log_like = np.dot(f, t) - np.sum(np.log(1+np.exp(f)), 1).reshape((n*n,1))\n",
        "log_joint = log_like.reshape((n*n,1)) + log_prior.reshape((n*n,1))\n",
        "\n",
        "\n",
        "plt.contour(xx, yy, -1*log_like.reshape((n,n)), 30)\n",
        "plt.title(\"Log-Likelihood\")\n",
        "\n",
        "#plotto  i punti corrispondenti agli iperpiani separatori\n",
        "for ii in range(0, ws.shape[0]):\n",
        "    w = np.transpose(ws[ii, :])\n",
        "    plt.annotate(str(ii+1), xy=(w[0], w[1]), color=col[ii])\n",
        "\n",
        "j=np.argmax(log_like)\n",
        "wmle = W[j, :]\n",
        "slope = wmle[1] / wmle[0]\n",
        "\n",
        "plt.plot([0, 7.9], [0, 7.9*slope])\n",
        "plt.grid()\n",
        "plt.savefig('bayesian_2_.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0qm1DSi1kWo"
      },
      "outputs": [],
      "source": [
        "#log distrib a posteriori non normalizzata\n",
        "plt.contour(xx,yy,-1*log_joint.reshape((n,n)), 30)\n",
        "plt.title(\"Log distribuz. a posteriori non normalizzata\")\n",
        "j2=np.argmax(log_joint)\n",
        "wb = W[j2][:]\n",
        "plt.scatter(wb[0], wb[1], c='red' , s = 100)\n",
        "plt.grid()\n",
        "plt.savefig('bayesian_3_.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzLhT0wP1_z_"
      },
      "outputs": [],
      "source": [
        "#approssimazione di laplace\n",
        "#https://bayes-logistic.readthedocs.io/en/latest/usage.html\n",
        "wfit, hfit = bayes_logistic.fit_bayes_logistic(t.reshape((N*D)), X, np.zeros(D), ((np.identity(D))*1/alpha), weights=None, solver='Newton-CG', bounds=None, maxiter=100)\n",
        "co = np.linalg.inv(hfit)\n",
        "\n",
        "log_laplace_posterior = np.log(multivariate_normal.pdf(W, mean = wfit, cov=co))\n",
        "plt.contour(xx, yy, -1*log_laplace_posterior.reshape((n,n)), 30)\n",
        "plt.scatter(wb[0], wb[1], c='red' , s = 100)\n",
        "plt.title(\"Approssimazione di Laplace alla distr. a posteriori\")\n",
        "plt.grid()\n",
        "plt.savefig('bayesian_4_.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lD5Ra5NQ2Ovr"
      },
      "outputs": [],
      "source": [
        "#p(y = 1 | x, wMAP)\n",
        "pred = 1.0/(1+np.exp(np.dot(-Xgrid,wfit)))\n",
        "plt.contour(xx, yy, pred.reshape((n,n)), 30)\n",
        "x_1, y_1 = X[np.where(t == 1)[0]].T\n",
        "x_2, y_2 = X[np.where(t == 0)[0]].T\n",
        "plt.scatter(x_1, y_1, c='red', s=20, marker='o')\n",
        "plt.scatter(x_2, y_2, c = 'blue', s=40, marker = 'o')\n",
        "plt.title(\"p(y=1|x, wMAP)\")\n",
        "plt.savefig('approx_1_.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74G-NRPR2KqX"
      },
      "outputs": [],
      "source": [
        "#Decision boundary per w campionati\n",
        "plt.scatter(x_1, y_1, c='red', s=20, marker='o')\n",
        "plt.scatter(x_2, y_2, c='blue', s=20, marker='o')\n",
        "predm = np.zeros((n*n,1))\n",
        "s = 100\n",
        "for i in range(s):\n",
        "    wsamp = np.random.multivariate_normal(mean = wfit, cov=co)\n",
        "    pred = 1.0/(1+np.exp(np.dot(-Xgrid,wsamp)))\n",
        "    predm = np.add(predm, pred.reshape((n*n, 1)))\n",
        "    plt.contour(xx, yy, pred.reshape((n,n)), np.array([0.5]))\n",
        "plt.title(\"Decision boundary per w campionati dalla distr. pred. a posteriori\")\n",
        "plt.savefig('approx_2_.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VtfyFEaG2US2"
      },
      "outputs": [],
      "source": [
        "#MC\n",
        "predm = predm/s\n",
        "plt.contour(xx, yy, predm.reshape((n,n)), 30)\n",
        "plt.scatter(x_1, y_1, c='red', s=20, marker='o')\n",
        "plt.scatter(x_2, y_2, c='blue', s=20, marker='o')\n",
        "plt.title(\"MC appross. di p(y=1|x)\")\n",
        "plt.savefig('approx_3_.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbNRL0GEyI0h"
      },
      "outputs": [],
      "source": [
        "#Approccio deterministico\n",
        "plt.scatter(x_1, y_1, c='red', s=20, marker='o')\n",
        "plt.scatter(x_2, y_2, c='blue', s=20, marker='o')\n",
        "pr = bayes_logistic.bayes_logistic_prob(Xgrid, wfit, hfit)\n",
        "plt.contour(xx, yy, pr.reshape((n, n)), 30)\n",
        "plt.title(\"Proibit approximation\")\n",
        "plt.savefig('approx_4_.png')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sigmoid vs Proibit"
      ],
      "metadata": {
        "id": "9fwoSsg9QCvB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.arange(-6, 6, 0.1)\n",
        "l = np.sqrt(np.pi/8); \n",
        "plt.plot(x, expit(x), 'r-', label='sigmoid')\n",
        "plt.plot(x, norm.cdf(l*x), 'g--', label='probit')\n",
        "\n",
        "plt.axis([-6, 6, 0, 1])\n",
        "plt.legend()\n",
        "plt.savefig('sigmoid.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MM-tdg5AQJXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6T1nT79CVIxu"
      },
      "source": [
        "\n",
        "##**Problema dello spam**\n",
        "\n",
        "In questa sezione il codice è tutta farina del mio sacco.\n",
        "\n",
        "Ovviamente mi sono aiutato con le librerie e la relativa documentazione "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIj63nH7gUn7"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlPgHw8pgDdk"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLRoHwibVGlW"
      },
      "outputs": [],
      "source": [
        "#carico i dati\n",
        "names = [1 + x for x in range(58)]\n",
        "names[57] = 'target'\n",
        "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data',\n",
        "                   names = names)\n",
        "data_x, data_y = data.drop('target', axis = 1), data['target']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PypxXjN0Xc6A"
      },
      "outputs": [],
      "source": [
        "#vedo le prime osservazioni per farmi un'idea dei dati\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOkxN3OsbXu5"
      },
      "outputs": [],
      "source": [
        "#vedo la proporzione tra 0 e 1 e osservo che c'è bisogno di stratification\n",
        "data['target'].value_counts()\n",
        "sns.countplot(x='target', data=data, palette='hls')\n",
        "plt.savefig('stratification')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SzinEBEzdboj"
      },
      "outputs": [],
      "source": [
        "#divido in training e test dopo aver fatto shuffling\n",
        "X, y = shuffle(data_x, data_y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=42,\n",
        "                                                    stratify=y)\n",
        "sc = StandardScaler()\n",
        "sc.fit(X_train)\n",
        "X_train = sc.transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.value_counts()"
      ],
      "metadata": {
        "id": "GAZg1nCHsLkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.value_counts()"
      ],
      "metadata": {
        "id": "62O66GOdsaci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model selection"
      ],
      "metadata": {
        "id": "C0ioe6v5WWo3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0kDW6JsYqLB"
      },
      "outputs": [],
      "source": [
        "#definisco l'architettura\n",
        "def create_model_sgd(learning_rate, momentum, k_reg):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(1,\n",
        "                    input_dim=57,\n",
        "                    activation='sigmoid',\n",
        "                    kernel_initializer= \"uniform\",\n",
        "                    kernel_regularizer=regularizers.l2(k_reg)))\n",
        "    optimizer = tf.keras.optimizers.SGD(lr=learning_rate, momentum=momentum)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjKEQlNjygj_"
      },
      "outputs": [],
      "source": [
        "#prima grid search\n",
        "np.random.seed(42)\n",
        "model = KerasClassifier(build_fn=create_model_sgd, epochs = 150, batch_size = 40)\n",
        "param_grid ={\"learning_rate\": [0.01, 0.05, 0.1],\n",
        "             \"momentum\": [0.1, 0.2, 0.3],\n",
        "             \"k_reg\": [0.00001, 0.0001, 0.001]}\n",
        "model_cv = GridSearchCV(model,\n",
        "                        param_grid,\n",
        "                        scoring = None,\n",
        "                        n_jobs=-1,\n",
        "                        cv = 3,\n",
        "                        verbose = 10)\n",
        "model_result = model_cv.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#vedo i migliori parametri\n",
        "model_cv.best_params_"
      ],
      "metadata": {
        "id": "xF5Qs2nz6mr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "means = model_result.cv_results_['mean_test_score']\n",
        "stds = model_result.cv_results_['std_test_score']\n",
        "params = model_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) con: %r\" % (mean, stdev, param))"
      ],
      "metadata": {
        "id": "Uro_CD2PwzdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#risultato grid search\n",
        "{'k_reg': 0.0001, 'learning_rate': 0.05, 'momentum': 0.3}"
      ],
      "metadata": {
        "id": "FBcthq9fgEYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model assessment"
      ],
      "metadata": {
        "id": "MNYGxyJ7Z0m0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def final_model_sgd():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(1, input_dim=57, activation='sigmoid', kernel_initializer= \"uniform\", kernel_regularizer=regularizers.l2(0.0001)))\n",
        "    optimizer = tf.keras.optimizers.SGD(lr=0.05, momentum=0.3)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "m2xF8ApcFOJI"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_model = KerasClassifier(build_fn=final_model_sgd)\n",
        "history = true_model.fit(X_train, y_train,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    epochs=150,\n",
        "                    batch_size=40)"
      ],
      "metadata": {
        "id": "yFxlfM-azN1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#learning curve\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training', 'test'], loc='upper left')\n",
        "plt.savefig('learning_curve')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sTPlTX_fHw_5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "SeminarioStatSup.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}